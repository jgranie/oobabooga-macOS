#!/usr/bin/env python

import nltk
import sys
#nltk.download('punkt')  # Download the Punkt tokenizer models

def tokenize_text(text):
    tokens = nltk.word_tokenize(text)
    return len(tokens)

# Check if filename is passed as argument
if len(sys.argv) > 1:
    filename = sys.argv[1]
    with open(filename, 'r') as file:
        text = file.read()
        num_tokens = tokenize_text(text)
        print(f"Number of tokens in file: {num_tokens}")
# If no filename is passed, read from STDIN
else:
    text = sys.stdin.read()
    num_tokens = tokenize_text(text)
    print(f"Number of tokens from STDIN: {num_tokens}")

